{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1.\n",
    "\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "\n",
    "time.sleep(0.2)\n",
    "\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "request = requests.get('https://habr.com/ru/all/')\n",
    "\n",
    "request_parsed = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "posts = request_parsed.find_all('article', class_='post post_preview')\n",
    "\n",
    "\n",
    "for post in posts:\n",
    "    post_date = post.find('span', class_='post__time').text\n",
    "    post_header = post.find('a', class_='post__title_link').text\n",
    "    post_link = post.find('a').get('href')\n",
    "    post_preview = post.find('div', class_ = 'post__text').text\n",
    "    for keyword in KEYWORDS:\n",
    "        if keyword in post_preview:\n",
    "            row = {'Дата': post_date, 'Заголовок': post_header, 'Ссылка': post_link}\n",
    "            result = pd.concat([result, pd.DataFrame([row])]) \n",
    "    \n",
    "    \n",
    "    \n",
    "result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.\n",
    "\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода: EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Почта</th>\n",
       "      <th>Дата публикации утечки</th>\n",
       "      <th>Источник утечки</th>\n",
       "      <th>Описание утечки</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2019-03-20T00:00:00Z</td>\n",
       "      <td>bookmate.com</td>\n",
       "      <td>In July 2018, Bookmate was allegedly breached....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2016-10-26T00:00:00Z</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>Login credentials for over 32 Million Twitter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2020-07-23T00:00:00Z</td>\n",
       "      <td>wattpad.com</td>\n",
       "      <td>In June 2020, the online writing community Wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2018-12-13T00:00:00Z</td>\n",
       "      <td>houzz.com</td>\n",
       "      <td>In July 2018, the housing site Houzz was alleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2016-12-15T00:00:00Z</td>\n",
       "      <td>vedomosti.ru</td>\n",
       "      <td>In May 2012, Russian business newspaper Vedomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2016-11-01T00:00:00Z</td>\n",
       "      <td>qip.ru</td>\n",
       "      <td>In 2011, Russian instant messaging service pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>info@avtosdelka.su</td>\n",
       "      <td>2020-12-03T00:00:00Z</td>\n",
       "      <td>chelyabinsk-gid.info</td>\n",
       "      <td>In November 2020, a collection of over 23,000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2020-12-10T00:00:00Z</td>\n",
       "      <td>webscript.rusmf</td>\n",
       "      <td>In November 2020, a collection of over 23,000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2019-09-12T00:00:00Z</td>\n",
       "      <td>xrumer.winguild.ru</td>\n",
       "      <td>At an unconfirmed date, Russian audio equipmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2017-01-16T00:00:00Z</td>\n",
       "      <td>fl.ru</td>\n",
       "      <td>In February 2015, FL.ru's entire site database...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>info@avtosdelka.su</td>\n",
       "      <td>2020-12-10T00:00:00Z</td>\n",
       "      <td>megapolis-99.ru</td>\n",
       "      <td>In November 2020, a collection of over 23,000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pbaholdin@mail.ru</td>\n",
       "      <td>2019-05-23T00:00:00Z</td>\n",
       "      <td>livejournal.com</td>\n",
       "      <td>In 2017, social network LiveJournal's database...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Почта Дата публикации утечки       Источник утечки  \\\n",
       "0    pbaholdin@mail.ru   2019-03-20T00:00:00Z          bookmate.com   \n",
       "1    pbaholdin@mail.ru   2016-10-26T00:00:00Z           twitter.com   \n",
       "2    pbaholdin@mail.ru   2020-07-23T00:00:00Z           wattpad.com   \n",
       "3    pbaholdin@mail.ru   2018-12-13T00:00:00Z             houzz.com   \n",
       "4    pbaholdin@mail.ru   2016-12-15T00:00:00Z          vedomosti.ru   \n",
       "5    pbaholdin@mail.ru   2016-11-01T00:00:00Z                qip.ru   \n",
       "6   info@avtosdelka.su   2020-12-03T00:00:00Z  chelyabinsk-gid.info   \n",
       "7    pbaholdin@mail.ru   2020-12-10T00:00:00Z       webscript.rusmf   \n",
       "8    pbaholdin@mail.ru   2019-09-12T00:00:00Z    xrumer.winguild.ru   \n",
       "9    pbaholdin@mail.ru   2017-01-16T00:00:00Z                 fl.ru   \n",
       "10  info@avtosdelka.su   2020-12-10T00:00:00Z       megapolis-99.ru   \n",
       "11   pbaholdin@mail.ru   2019-05-23T00:00:00Z       livejournal.com   \n",
       "\n",
       "                                      Описание утечки  \n",
       "0   In July 2018, Bookmate was allegedly breached....  \n",
       "1   Login credentials for over 32 Million Twitter ...  \n",
       "2   In June 2020, the online writing community Wat...  \n",
       "3   In July 2018, the housing site Houzz was alleg...  \n",
       "4   In May 2012, Russian business newspaper Vedomo...  \n",
       "5   In 2011, Russian instant messaging service pro...  \n",
       "6   In November 2020, a collection of over 23,000 ...  \n",
       "7   In November 2020, a collection of over 23,000 ...  \n",
       "8   At an unconfirmed date, Russian audio equipmen...  \n",
       "9   In February 2015, FL.ru's entire site database...  \n",
       "10  In November 2020, a collection of over 23,000 ...  \n",
       "11  In 2017, social network LiveJournal's database...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "time.sleep(1)\n",
    "email_check = [\"pbaholdin@mail.ru\", \"info@avtosdelka.su\"]\n",
    "URL = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "params = {'emailAddresses': email_check}\n",
    "headers = {'Vaar-Version': '0', 'Vaar-Header-App-Product': 'hackcheck-web-avast'}\n",
    "request = requests.post(URL, headers = headers, json = params)\n",
    "dict_ = json.loads(request.text)\n",
    "\n",
    "#почта:\n",
    "#for key in dict_['summary']:\n",
    "    #print(key)\n",
    "    \n",
    "#утечка:\n",
    "breaches = []\n",
    "for key in dict_['breaches']:\n",
    "    breaches.append(key)\n",
    "    \n",
    "#источник утечки:\n",
    "breach_sources = []\n",
    "for key in dict_['breaches']:\n",
    "    breach_sources.append(dict_['breaches'][key]['site'])\n",
    "    \n",
    "#дата публикации\n",
    "postdates = []\n",
    "for key in dict_['breaches']:\n",
    "    postdates.append(dict_['breaches'][key]['publishDate'])\n",
    "    \n",
    "#описание утечки\n",
    "breach_descriptions = []\n",
    "for key in dict_['breaches']:\n",
    "    breach_descriptions.append(dict_['breaches'][key]['description'])\n",
    "    \n",
    "    \n",
    "#соотнесение почты и номера утечки:\n",
    "email_and_breach_number = {}\n",
    "for key, value in dict_['summary'].items():\n",
    "    if key not in email_and_breach_number:\n",
    "        email_and_breach_number[key] = value['breaches']\n",
    "\n",
    "\n",
    "parsed_data_dictionary = {'Утечка':breaches, 'Дата публикации утечки':postdates, 'Источник утечки':breach_sources, 'Описание утечки':breach_descriptions}\n",
    "\n",
    "Result = pd.DataFrame(parsed_data_dictionary)\n",
    "\n",
    "           \n",
    "#если номер утечки равен ключу - в столбец \"Почта\" подставляем значение словаря \n",
    "def email_of_the_breach(row):\n",
    "    for key, value in email_and_breach_number.items():\n",
    "        for i in value:\n",
    "            if str(i) == row:\n",
    "                return key\n",
    "    \n",
    "        \n",
    "Result['Почта'] = Result['Утечка'].apply(email_of_the_breach)\n",
    "\n",
    "Final_Result = Result.iloc[:, 1:5]\n",
    "\n",
    "neworder = ['Почта', 'Дата публикации утечки', 'Источник утечки', 'Описание утечки']\n",
    "\n",
    "Final_Result=Result.reindex(columns=neworder)\n",
    "\n",
    "Final_Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'xxx@x.ru': [{'breachId': 3176,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'xxx@x.ru': [{'breachId': 3,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}],\n",
       "  'yyy@y.com': [{'breachId': 3,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'xxx@x.ru': [{'breachId': 2961,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 17110,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 2,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 41,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 17670,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 3669,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 13094,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 3587,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 16768,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 3520,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'xxx@x.ru': [{'breachId': 3164,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'xxx@x.ru': [{'breachId': 12,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 13662,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'xxx@x.ru': [{'breachId': 15,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}],\n",
       "  'yyy@y.com': [{'breachId': 15,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " {'yyy@y.com': [{'breachId': 17009,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "time.sleep(1)\n",
    "EMAIL = ['xxx@x.ru', 'yyy@y.com']\n",
    "url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "headers = {'Vaar-Header-App-Product': 'hackcheck-web-avast','Vaar-Version': '0'}\n",
    "addresses = {'emailAddresses': EMAIL}\n",
    "res = requests.post(url, json=addresses, headers=headers)\n",
    "df = pd.DataFrame(res.json()['breaches']).T.reset_index() \n",
    "df = df[['site', 'description', 'publishDate']]\n",
    "df['email'] = [', '.join(el.keys()) for el in list(res.json()['data'].values())]\n",
    "\n",
    "list(res.json()['data'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
